简单理解k-means:
k-means 聚类是聚类算法中最经典基础性算法，是一种基于无监督进行样本分类的方法。通常分为一下几个步骤
（1） 聚类类别的选择。
    对于确定性事件聚类，如个人征信，收入等级，犯罪如否等聚类一般有确定性类别，但是对于问题中没有指定具体的K值时，
一般可以使用肘部法则把不同值的成本函数值画出来。随着值的增大，平均畸变程度会减小；每个类包含的样本数会减少，于是样本离其重心会更近。
但是，随着值继续增大，平均畸变程度的改善效果会不断减低。值增大过程中，畸变程度的改善效果下降幅度最大的位置对应的值就是肘部。
另外，还可以使用canopy算法进行寻找最有聚类数量。
（2） 初始质心的选择。
    常见的方法是随机的选取初始中心，但是这样簇的质量常常很差。处理选取初始质心问题的一种常用技术是：多次运行，每次使用一组不同的随机初始质心，
然后选取具有最小SSE(误差的平方和)的簇集。这种策略简单，但是效果可能不好，这取决于数据集和寻找的簇的个数；
（3） 在第K次迭代中，对任意一个样本，求其到C各中心的距离，将该样本归到距离最短的中心所在的类；
（4） 利用均值等方法更新该类的中心值
（5） 对于所有的C个聚类中心，如果利用（3）（4）的迭代法更新后，值保持不变，则迭代结束，否则继续迭代


例子：
  例如现在有四种药物A,B,C,D，他们分别有两个属性：
  
  类别   X    Y
  A     1     1
  B     2     1
  C     3     4
  D     4     5
  
  第一次迭代，随机选取两个点作为初始中心点，eg c1,c2作为初始中心点，D0中分别为四个点到两个样本点的距离：
  D0 = [[0,1],
        [1,0],
        [3.61,2.82],
        [5,4.24]] #c1=[1,1],c2=[2,1]
  第一次迭代完成后分到c1 类别的有A,分到c2类别的有B,C,D.此时中心点变为：
  c1 = A= [1,1],c2=[(B[X]+C[X]+D[X])/3,(B[Y]+C[Y]+D[Y])/3]=[3,10/3]
  
  第二次迭代：
  D1 = [[0,(4+49/9)^1/2],
        [1,(1+49/9)^1/2],
        [13^1/2,2/3],
        [5,(1+25/9)^1/2]] #c1=[1,1],c2=[3,10/3]
  第二次迭代完成后分到c1 类别的有A,B,分到c2类别的有C,D.此时中心点变为：
   c1 = (A+B)/2=[3/2,1], c2 = [7/2,9/2]
   
   第三次迭代:
   D2 = [[1/2,(4+49/9)^1/2],
         [1/2,(1+49/9)^1/2],
         [(9+9/4)^1/2,2/3],
         [(25/4+16)^1/2,(1+25/9)^1/2]] #c1 = [3/2,1], c2 = [3,10/3]
   
   第三次迭代完成后分到c1 与 c2 类别不变，迭代停止。
   
   
  
  
  
  
